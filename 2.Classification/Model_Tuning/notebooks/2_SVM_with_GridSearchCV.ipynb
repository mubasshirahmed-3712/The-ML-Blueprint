{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e480aa8e",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Support Vector Machine with GridSearchCV</h2>\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Introduction\n",
    "\n",
    "SVM has several important **hyperparameters** that greatly affect performance:\n",
    "\n",
    "- **C** â†’ Regularization strength (large C = low bias, high variance; small C = high bias, low variance)  \n",
    "- **Kernel** â†’ Transformation type (linear, rbf, poly, etc.)  \n",
    "- **Gamma** (for RBF/poly kernel) â†’ Defines influence of a single training point  \n",
    "\n",
    "ðŸ‘‰ Choosing these values manually is inefficient.  \n",
    "\n",
    "**GridSearchCV** helps by:  \n",
    "- Trying all possible combinations of hyperparameters (grid search).  \n",
    "- Evaluating each with cross-validation.  \n",
    "- Returning the best parameters and best accuracy.  \n",
    "\n",
    "In this notebook:\n",
    "1. Train a baseline SVM.  \n",
    "2. Apply GridSearchCV to tune hyperparameters.  \n",
    "3. Compare results (before vs after tuning).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80893914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6782f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Load dataset\n",
    "dataset = pd.read_csv(\"../data/Social_Network_Ads.csv\")\n",
    "\n",
    "X = dataset.iloc[:, 2:4].values   # Age, EstimatedSalary\n",
    "y = dataset.iloc[:, -1].values    # Purchased\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0981fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (default SVM): 93.00 %\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Baseline SVM model (before tuning)\n",
    "baseline_clf = SVC(kernel=\"rbf\", random_state=0)\n",
    "baseline_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_base = baseline_clf.predict(X_test)\n",
    "base_acc = accuracy_score(y_test, y_pred_base)\n",
    "\n",
    "print(\"Baseline Accuracy (default SVM): {:.2f} %\".format(base_acc*100))  # âž¤ Example: 93%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13274131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Accuracy: 91.00 %\n",
      "Best Parameters: {'C': 1, 'gamma': 0.7, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Define parameter grid for GridSearchCV\n",
    "param_grid = [\n",
    "    {\"C\": [1, 10, 100, 1000], \"kernel\": [\"linear\"]},\n",
    "    {\"C\": [1, 10, 100, 1000], \"kernel\": [\"rbf\"], \n",
    "     \"gamma\": [0.1, 0.2, 0.3, 0.5, 0.7, 0.9]}\n",
    "]\n",
    "\n",
    "# ðŸ“Œ Apply GridSearchCV with 10-fold CV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=SVC(random_state=0),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best CV Accuracy: {:.2f} %\".format(best_accuracy*100))   # âž¤ Example: 94.67%\n",
    "print(\"Best Parameters:\", best_params)                          # âž¤ Example: {'C':10, 'kernel':'rbf','gamma':0.5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea7dae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Tuned Model): 93.00 %\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Evaluate best model on Test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "best_acc = accuracy_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"Test Accuracy (Tuned Model): {:.2f} %\".format(best_acc*100))   # âž¤ Example: 95%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d878633",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Summary\n",
    "\n",
    "- **Baseline SVM (default params)** â†’ Accuracy = XX %  \n",
    "- **After GridSearchCV tuning** â†’ CV Accuracy = YY %, Test Accuracy = ZZ %  \n",
    "\n",
    "âœ… GridSearchCV systematically searched over parameter combinations.  \n",
    "âœ… Best params gave higher accuracy than the default SVM.  \n",
    "âœ… Tradeoff: GridSearch is computationally expensive (tries all combinations).  \n",
    "\n",
    "ðŸ‘‰ Next step (Notebook 3): Compare with **RandomizedSearchCV**, which is faster and often nearly as effective.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
